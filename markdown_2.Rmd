---
title: "Precios al consumidor"
author: "Manuel Toledo y Lucas Pescetto"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
library(readr)
library(here)
library(tidyverse)
library(sf)
library(terra)
library(lubridate)
library(RColorBrewer)
library(xgboost)
library(caret)
```

# Introducción

Este proyecto surge a partir de la información provista por el SIPC (Sistema de Información de Precios al Consumidor) del Ministerio de Economía y Finanzas. Este organismo brinda información acerca de los precios de una serie de productos a través del tiempo y para distintos establecimientos en todos los departamentos de Uruguay.

Por otro lado, a raíz de la amplia diversidad de los productos de los cuales se tienen datos, se decidió tomar solamente aquellos que son parte de la CBA (Canasta Básica de Alimentos) de Uruguay.

El objetivo del trabajo es generar un análisis y visualizaciones que permitan ver las variaciones en los precios de dichos productos a lo largo del tiempo, en distintos lugares dentro del país y en establecimientos dentro de Montevideo. Esto resultaría de utilidad para ayudar a los consumidores a tomar mejores decisiones financieras a la hora de comprar alimentos.

# Datos

El SIPC presenta los datos en tres datasets:

- Establecimientos: es una lista de los establecimientos de los cuales se obtienen los precios. Se obtiene en la web de Catálogo abierto de datos.
- Productos: es una lista de los productos de los cuales se tienen los precios. Se obtiene en la web de Catálogo abierto de datos.
- Precios: contiene la información acerca de los precios registrados en cada momento del tiempo, para cada producto en cada establecimiento. Si bien se puede obtener en la web de Catálogo abierto de datos, debido a su tamaño se extrae con una consulta SQL.

A continuación se muestra una tabla con las variables de cada dataset:

(tablas)

Se cuenta con datos a partir del año 2016 y hasta marzo del 2023. Estos contienen 363 productos dentro 766 establecimientos. De esos, solamente se usarán los 18 productos dentro de la CBA más 2 productos que se agregaron por decisión personal (para cada producto existen varias marcas).  
Los productos son:

- Aceite de girasol 900 cc
- Aguja vacuna 1 kg (con y sin hueso)
- Arroz blanco 1 kg
- Arvejas en conserva 300 g
- Azúcar blanco 1 kg
- Carne picada vacuna 1 kg ***
- Cocoa 500 g
- Dulce de leche 1 kg
- Fideos secos al huevo 500 g ***
- Galletitas al agua 140 g ***
- Harina trigo común 0000  1 kg
- Huevos colorados 1/2 docena
- Manteca 200 g
- Pan flauta 215 g
- Papel higiénico hoja simple 4 rollos 30 mts
- Pollo entero fresco con menudos 1 kg
- Pulpa de tomate 1 L
- Sal fina yodada fluorada 500 g
- Yerba mate común 1 kg ***
- Café (agregado)
- Fideos secos de sémola 500 g (agregado)

A partir de los datasets, se construyó uno con el precio promedio mensual para cada producto (desagregándolo según las marcas y establecimientos), que incluyera parte de la información presente en Establecimientos (el nombre de la sucursal, cadena, coordenadas, barrio y departamento) y Productos (nombre y marca). Para eso se utilizaron las *keys* respectivas, id.establecimientos e id_productos.

```{r consulta SQL, eval = F}
usethis::edit_r_environ(
  scope = "project"
)

con <- DBI::dbConnect(
  RPostgres::Postgres(),
  host = Sys.getenv("DB_HOST"),
  port = Sys.getenv("DB_PORT"),
  user = Sys.getenv("DB_USER"),
  password = Sys.getenv("DB_PASS"),
  dbname = Sys.getenv("DB_NAME")
)


precios_canasta <- DBI::dbGetQuery(
  con,
  "
  SELECT
    fact_price.id_producto,
    id_establecimientos,
    AVG(precio),
    EXTRACT(year from fecha) * 100 + EXTRACT(month from fecha) as year_month
  FROM
    scraping_precios.fact_price
  LEFT JOIN
    d_productos ON fact_price.id_producto = d_productos.id_producto
  WHERE
    fact_price.id_producto IN (1,2,3,13,14,15,16,17,18,19,20,21,23,22,24,25,29,30,40,41,48,49,50,52,53,54,61,62,76,77,78,85,86,87,102,103,104,121,122,123,124,130,131,132,133,134,135,140,141,142,149,150,151,359,361,365,26,27,28,55,56,57) 
  GROUP BY fact_price.id_producto, id_establecimientos, EXTRACT(year from fecha) * 100 + EXTRACT(month from fecha)
  "
)
```

```{r preprocesamiento y datos auxiliares, eval = F}
establecimientos <- read_delim("datos/establecimiento.csv", delim = ";", locale = locale(encoding = "latin1")) %>% 
  select(id.establecimientos, nombre.sucursal, barrio, cadena, long, lat, depto, id.depto) %>% 
  mutate(lat=as.numeric(sub(',','.',lat,fixed=T)),
         long=as.numeric(sub(',','.',long,fixed=T)),
         # arreglamos Ta Ta que le faltaba el signo 
         long = ifelse(long > 0, -34.88675, long),
         # arreglamos San Roque del aeropuerto, que estaba mal
         long = ifelse(id.establecimientos == 679, -34.83675, long),
         lat = ifelse(id.establecimientos == 679, -56.01600, lat))

productos <- read_csv2("datos/productos.csv", locale = readr::locale(encoding = "latin1")) %>% 
  select(id.producto, producto, marca, nombre) 

precios_canasta <- left_join(precios_canasta, establecimientos, by = c("id_establecimientos" = "id.establecimientos")) %>% 
  left_join(productos, by = c("id_producto" = "id.producto")) %>% 
  filter_at(c("long", "lat"), function(x) !is.na(x)) %>% 
  mutate(year_month=as.Date(ym(paste(str_sub(year_month,start=1,end=4),str_sub(year_month,start=5,end=6),sep="-"))))

precios_canasta <- st_as_sf(precios_canasta, coords = c("lat", "long")) %>% 
  st_set_crs(4326) %>% 
  as.data.frame()

saveRDS(precios_canasta, "precios_canasta.RDS")
```

```{r cargar datos}
precios <- readRDS(here("precios_canasta.RDS"))

df_depto <- st_as_sf(vect(here("Mapas","ine_depto.shp"))) %>% st_set_crs(5382) %>%  st_transform(4326)

df_mvdeo <- st_as_sf(vect(here("Mapas","ine_ccz_mvd.shp")))
```

# Análisis exploratorio

```{r eval = F}

ggplot(filter(precios,id_producto %in% 55:57 & id_establecimientos == 2),aes(x=year_month,y=avg)) + geom_point() + geom_smooth()

```

Evolución de precios de las distintas marcas de fideos

```{r}
precios %>% 
  filter(id_producto %in% 55:57 & avg > 0) %>% 
  group_by(id_producto, year_month) %>% 
  summarise(precio = mean(avg)) %>% 
  ggplot(aes(x = year_month, y = precio, color = as.factor(id_producto))) +
  geom_line(linewidth = 1) +
  geom_point()
```

Mapa de los establecimientos

```{r mapa_establecimientos}
ggplot() + 
  geom_sf(data=df_depto,fill=NA,color="gray20") +
  geom_sf(data=precios %>% filter(!duplicated(geometry)), aes(geometry = geometry), pch=4,color="red") +
  theme_void() +
  labs(title="Establecimientos") +
  theme(plot.title=element_text(hjust=1/2))
```

Mapa del precio promedio de los fideos según departamento

```{r mapa_precios}
fideos_dpto <- precios %>% 
  filter(id_producto %in% c(55, 56, 57)) %>% 
  group_by(id.depto) %>% 
  summarise(precio = mean(avg))

ggplot(data=df_depto %>% left_join(fideos_dpto, by = c("DEPTO" = "id.depto"))) + 
  geom_sf(aes(fill=precio),color="gray20") +
  scale_fill_gradientn(colours = brewer.pal(5, "OrRd")) +
  theme_void() +
  labs(title="Establecimientos") +
  theme(plot.title=element_text(hjust=1/2))



```


# Modelo estadístico

USAMOS ESTO PARA HACER EL MODELO:

XGBOOST TIME SERIES FORECAST IN R
http://datasideoflife.com/?p=1009

Predicción del modelo inicial:

```{r}
fideos <- precios %>% 
  filter(id_producto %in% c(55, 56, 57)) %>% 
  group_by(year_month) %>% 
  summarise(precio = mean(avg)) %>% 
  mutate(year = year(year_month),
         month = month(year_month), .before = 1) %>% 
  add_case(year = c(rep(2023, 9), rep(2024, 12)), month = c(4:12, 1:12)) 

x_train <- fideos %>% filter(!is.na(precio)) %>% select(year, month) %>% as.matrix()

y_train <- c(fideos %>% filter(!is.na(precio)) %>% select(precio))[[1]]

x_pred <- fideos %>% filter(is.na(precio)) %>% select(year, month) %>% as.matrix()

xgb_trcontrol <- caret::trainControl(
  # metodo para sacar la remuestra
  method = "boot",
  # method = "cv", 
   number = 5,
   allowParallel = TRUE,
   returnData = FALSE
)

xgb_grid <- base::expand.grid(
   list(
    nrounds = c(100, 200),
    max_depth = c(10, 15, 20), # maximum depth of a tree
    colsample_bytree = seq(0.5), # subsample ratio of columns when construction each tree
    eta = 0.1, # learning rate
    gamma = 0, # minimum loss reduction
    min_child_weight = 1,  # minimum sum of instance weight (hessian) needed ina child
    subsample = 1 # subsample ratio of the training instances
))

xgb_model <- caret::train(
   x_train, y_train,
   trControl = xgb_trcontrol,
   tuneGrid = xgb_grid,
   method = "xgbTree",
   nthread = 1
)

xgb_pred <- xgb_model %>% stats::predict(x_pred)

fideos <- fideos %>% mutate(precio = c(y_train, xgb_pred),
                            year_month = as.Date(ym(paste(year, "-", month))),
                            pred = ifelse(year_month < "2023-04-01", F, T))

ggplot(data = fideos, aes(x = year_month, y = precio, color = pred)) +
  geom_point() +
  scale_color_manual("Valores predichos", labels = c("NO", "SI"), values = c("black", "red"))

```
```{r}
# Descripción de la aplicación



# Cosas


# mostrar la evolución de los precios ajustando por inflación
# 
# Mapa con los supermercados
# 
# Hacer una canasta y mostrar el mejor local
# 
# 
# 
# 
# 
# Aceite de girasol 900 cc = 1:3,357,359,363
# Aguja vacuna 1 Kg	= 13 (con hueso) 14 (sin hueso)
# Arroz blanco 1 Kg	= 15:20
# Arvejas en conserva 300 grs = 21,23 (300g) y 22 (380g)
# Azúcar blanco 1 Kg	= 24:25
# Carne picada vacuna 1 Kg	= 29:30
# Cocoa 500 grs	= 40:41
# Dulce de leche 1 Kg	= 48:50
# Fideos secos al huevo 500 grs	= 52:54
# Galletitas al agua 140 grs	= 61 (140g) 62(120g)
# Harina trigo común 0000  1 kg	= 76:78
# Huevos colorados 1/2 docena	= 85:87
# Manteca 200 grs	= 102:104
# Pan flauta 215 grs	= 121
# Papel higiénico hoja simple 4 rollos 30 mts	= 122:124
# Pollo entero fresco con menudos 1 kg	= 130:132
# Pulpa de tomate 1 Lt	= 133:135
# Sal fina yodada fluorada 500 grs	= 140:142
# Yerba mate común 1 Kg	= 149:151
# 
# EXTRA:
# café = 26:28
# fideos de sémola = 55:57

```